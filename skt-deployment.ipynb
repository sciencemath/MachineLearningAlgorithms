{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b935e1-df61-448c-858c-8f75453ff9ff",
   "metadata": {},
   "source": [
    "we've used `model.save()` before now to version the model we can create a subdirectory for each model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b997eb9-a204-4ee8-98d6-9ca6b7c6cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values (0-255) to the range [0,1]\n",
    "X_train_full = X_train_full.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape for CNN input (adding channel dimension)\n",
    "X_train_full = X_train_full[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "X_train, X_valid = X_train_full[:50000], X_train_full[50000:]\n",
    "y_train, y_valid = y_train_full[:50000], y_train_full[50000:]\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")  # Output layer for 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Save the trained model\n",
    "model_name = \"my_mnist_model\"\n",
    "model_version = \"0001\"\n",
    "model_dir = Path(model_name)\n",
    "model_dir.mkdir(parents=True, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "model_path = model_dir / f\"{model_version}.keras\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e27ee-f869-405c-916d-0a283e3c478c",
   "metadata": {},
   "source": [
    "metagraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b2223b0-46cd-44d7-8edb-fa5a79a915f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !saved_model_cli show --dir ./my_mnist_model/0001.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e812379-f632-46eb-ac0c-487a76bb68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !saved_model_cli show --dir ./my_mnist_model/0001.keras --tag_set serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02901104-55f5-4734-a0e1-c798f99d3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !saved_model_cli show --dir ./my_mnist_model/0001.keras --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210bbf4-a688-4b97-a231-05afdd5c684e",
   "metadata": {},
   "source": [
    "using Docker locally:\n",
    "\n",
    "`docker pull tensorflow/serving`\n",
    "\n",
    "`docker run -p 8501:8501 --name=tf_serving --mount type=bind,source=/Users/mathias/Documents/research2025/MachineLearningAlgorithms/my_mnist_model,target=/0001.keras -e MODEL_NAME=0001 -t tensorflow/serving`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b4b0b4b-49ef-4caa-bbe4-7fa3cd1fc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://storage.googleapis.com/tensorflow-serving-apt\"\n",
    "# src = \"stable tensorflow-model-server tensorflow-model-server-universal\"\n",
    "# !echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list\n",
    "# !curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -\n",
    "# !apt update -q && apt-get install -y tensorflow-model-server\n",
    "# !pip install -q -U tensorflow-serving-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "314e21e1-a278-44e2-9d23-b976d536ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MODEL_DIR\"] = str(model_path.parent.absolute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63449d54-0f69-4487-ba74-848735c42423",
   "metadata": {},
   "source": [
    "Starting the server using the `MODEL_DIR` environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44c6e0de-abd3-4017-b50f-46d733e74076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash --bg\n",
    "# tensorflow_model_server \\\n",
    "# --port=8500 \\\n",
    "# --rest_api_port=8501 \\\n",
    "# --model_name=my_mnist_model \\\n",
    "# --model_base_path=\"${MODEL_DIR}\" >my_server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f49ad33d-02db-4f87-a799-3dac309ee55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert input images from NumPy array to Python list\n",
    "import json\n",
    "\n",
    "# X_new = X_test[:3] # pretending we have 3 new digit images to classify\n",
    "# request_json = json.dumps({\n",
    "#     \"signature_name\": \"servering_defalt\",\n",
    "#     \"instances\": X_new.tolist(),\n",
    "# })\n",
    "\n",
    "# request_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa93e5c-1f05-461a-a335-44020f65c26e",
   "metadata": {},
   "source": [
    "Send this request to TF Serving via an HTTP POST request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ced6c3d9-f959-4bb7-9786-898ea503e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# server_url = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
    "# response = requests.post(server_url, data=request_json)\n",
    "# response.raise_for_status()\n",
    "# response = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c8148-8b85-4414-b6fe-e119cd9e5e0f",
   "metadata": {},
   "source": [
    "The corresponding value is the list of predictions. This list is a Python list, so let’s convert it to a NumPy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70e4c6e4-9915-4582-a6c3-6419a9e2b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# y_proba = np.array(response[\"predictions\"])\n",
    "# y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cacc9c-6c4a-4830-8bfc-959e2df185eb",
   "metadata": {},
   "source": [
    "### gRPC \n",
    "\n",
    "important when using large amounts of data and latency is important.\n",
    "\n",
    "Uses Http2 and binary format\n",
    "\n",
    "gRPC API expects a serialized `PredictRequest` protocol buffer as input, and it outputs a serialized `PredictResponse` protocol buffer. protobufs are part of the tensorflow-serving-api library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4f27a33-d9d2-47c9-b88c-4cb25dea81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow_serving.apis.perdict_pb2 import PredictRequest\n",
    "\n",
    "# request = PredictRequest()\n",
    "# request.model_spec.name = model_name\n",
    "# request.model_spec.signature_name = \"serving_default\"\n",
    "# input_name = model.input_names[0]\n",
    "# request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34338547-cb39-49f3-b6f4-5212976cf3ef",
   "metadata": {},
   "source": [
    "Creating a gRPC communication channel to localhost on TCP port 8500:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "347e5ec5-e4a0-4e26-b295-5e3cb4827faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import grpc\n",
    "# from tensorflow_servering.apis import prediction_service_pb2_grpc\n",
    "\n",
    "# channel = grpc.insecure_channel('localhost:8500')\n",
    "# predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "# response = predict_service.Predict(request, timeout=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336180cd-3185-4b10-aad0-77da7ff77ec6",
   "metadata": {},
   "source": [
    "covert PredictResponse protocol buffer to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "391f43e5-29f5-4607-af24-a571e64a6106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_name = model.output_names[0]\n",
    "# outputs_proto = response.outputs[output_name]\n",
    "# y_proba = tf.make_ndarray(outputs_proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c8d65-d315-4554-8034-8ffc9a27bb7d",
   "metadata": {},
   "source": [
    "The above allows us to access our TensorFlow model remotely, using either REST or gRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e60be9ee-c1e1-44c7-9e6e-b92ee64a12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"0002\"\n",
    "model_path = model_dir / f\"{model_version}.keras\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e2d584-747e-4d81-a402-7896162ff655",
   "metadata": {},
   "source": [
    "using code in a Google CoLab notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d3eb2f7-4d31-4668-987d-4119ac6d5b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e20b1d3f-c8d2-4716-bedb-b289c247c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# def upload_directory(bucket, dirpath):\n",
    "#   dirpath = Path(dirpath)\n",
    "#   for filepath in dirpath.glob(\"**/*\"):\n",
    "#     if filepath.is_file():\n",
    "#       blob = bucket.blob(filepath.relative_to(dirpath.parent).as_posix())\n",
    "#       blob.upload_from_filename(filepath)\n",
    "\n",
    "# upload_directory(bucket, \"my_mnist_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad66eec-c9ac-455b-93f3-6b9824a95d1e",
   "metadata": {},
   "source": [
    "upload `0001.keras` model to google cloud storage by creating a bucket and enabling Vertex AI API\n",
    "\n",
    "had to save a .pb model format when uploading container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bbc70cc-e6ad-40f4-b00b-ad4d32c80c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from google.cloud import storage\n",
    "\n",
    "# model = tf.keras.models.load_model(f\"gs://{bucket_name}/my_mnist_model/0001.keras\")\n",
    "\n",
    "# saved_model_path = f\"gs://{bucket_name}/my_mnist_model\"\n",
    "\n",
    "# tf.saved_model.save(model, saved_model_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dca2a4b-f589-4588-a93f-478fb62b68ee",
   "metadata": {},
   "source": [
    "then this finds the bucket and uploads the `saved_model.pb` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88942277-a01b-4b8d-aa34-381ee5c9156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import aiplatform\n",
    "\n",
    "# server_image = \"gcr.io/cloud-aiplatform/prediction/tf2-gpu.2-8:latest\"\n",
    "\n",
    "# aiplatform.init(project=project_id, location=location)\n",
    "# mnist_model = aiplatform.Model.upload(\n",
    "#     display_name=\"mnist\",\n",
    "#     artifact_uri=f\"gs://{bucket_name}/my_mnist_model\",\n",
    "#     serving_container_image_uri=server_image,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0dbc0ad9-a00e-46f4-a9ce-604568fb18f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = endpoint.predict(instances=X_new.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d4f47-d71a-44de-89f6-06191243dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.round(response.predictions, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0db051d-01f8-4b55-84d1-e3d7afc79414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint.undeploy_all() # undeploy all models from the endpoint\n",
    "# endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf097d5-ba2e-4c28-a1be-85950cac33cf",
   "metadata": {},
   "source": [
    "If we have a large number of predictions to make, then instead of calling our prediction service repeatedly, we can ask Vertex AI to run a prediction job for us. This does not require an endpoint, only a model. Create a\n",
    "file containing one instance per line, each formatted as a JSON value this format is called JSON Lines then pass this file to Vertex AI. So let's create a JSON Lines file in a new directory, then upload this directory to GCS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f922ad5b-aefa-4811-94de-824510d251b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_path = Path(\"my_mnist_batch\")\n",
    "# batch_path.mkdir(exist_ok=True)\n",
    "# with open(batch_path / \"my_mnist_batch.jsonl\", \"w\") as jsonl_file:\n",
    "#     for image in X_test[:100].tolist():\n",
    "#         jsonl_file.write(json.dumps(image))\n",
    "#         jsonl_file.write(\"\\n\")\n",
    "\n",
    "# upload_directory(bucket, batch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca81154-bede-47fb-a188-1d42cc90b699",
   "metadata": {},
   "source": [
    "use the json line file to run batch operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe1916ee-b195-495d-88e1-fd9cae38a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_prediction_job = mnist_model.batch_predict(\n",
    "#     job_display_name=\"mnist-batch-prediction-job\",\n",
    "#     machine_type=\"n1-standard-4\",\n",
    "#     starting_replica_count=1,\n",
    "#     max_replica_count=5,\n",
    "#     accelerator_type=\"NVIDIA_TESLA_K80\",\n",
    "#     accelerator_count=1,\n",
    "#     gcs_source=f\"gs://{bucket_name}/{batch_path.name}/my_mnist_batch.jsonl\",\n",
    "#     gcs_destination_prefix=f\"gs://{bucket_name}/my_mnist_predictions/\",\n",
    "#     sync=True # set to False if you don't want to wait for completion\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a67c9-584c-4a33-bb71-edc0677dcb10",
   "metadata": {},
   "source": [
    "iterate through all predictions in output files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bfcdb68-ad3d-40df-946b-b2bc0cd8eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "# accuracy = np.sum(y_pred == y_test[:100]) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1650bab3-72af-40cc-b017-b3a3d6934aac",
   "metadata": {},
   "source": [
    "delete the directories in bucked created in GCS bucket (optionally the bucket itself if empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3033f32e-0b6d-4ea8-8b18-68198cd0f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prefix in [\"my_mnist_model/\", \"my_mnist_batch/\", \"my_mnist_predictions/\"]:\n",
    "#     blobs = bucket.list_blobs(prefix=prefix)\n",
    "#     for blob in blobs:\n",
    "#         blob.delete()\n",
    "\n",
    "# bucket.delete() # if bucket is empty\n",
    "# batch_prediction_job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6135aa-9e52-4d4c-bde2-0681b716da98",
   "metadata": {},
   "source": [
    "convert a savedmodel to a flatbuffer and save it as a .tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ffaa3672-6fdf-4fc7-89c5-86d0ab1f318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter = tf.lite.TFLiteConverter.from_saved_model(str(model_path))\n",
    "# tflite_model = converter.convert()\n",
    "# with open(\"my_converted_savedmodel.tflite\", \"wb\") as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61128bcb-661a-4b33-aa40-cdaea99512d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee61ee-0f68-4809-a18f-3649f14ee1ac",
   "metadata": {},
   "source": [
    "JS Code for running tensorflow in browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c98b6908-2193-475d-bbd8-a29b0d219464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest\";\n",
    "# import \"https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@1.0.0\";\n",
    "\n",
    "# const image = document.getElementById(\"image\");\n",
    "# mobilenet.load().then(model => {\n",
    "#     model.classify(image).then(predictions => {\n",
    "#         predictions.forEach((pred, i) => {\n",
    "#             let className = pred.className\n",
    "#             let proba = (pred.probability * 100).toFixed(1)\n",
    "#             console.log(`${className} : ${proba}%`)\n",
    "#         })\n",
    "#     })\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b1d773a-996e-4ca8-96bb-313eeed7cc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "physical_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e26cb-8c9b-46ac-835f-0127f9d83a62",
   "metadata": {},
   "source": [
    "Training multiple models on multiple GPUs (split up the RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e463abc-d268-41fe-87e4-466e26d6fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in one terminal:\n",
    "# CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=0,1 python3 program_1.py\n",
    "\n",
    "# in another terminal:\n",
    "# CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=3,2 python3 program_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a87489b-beb2-4a3a-9eae-8967aa30699f",
   "metadata": {},
   "source": [
    "allocate specific amount of GPU RAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29cdfab6-4d2b-48fc-b292-e042731af6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gpu in pyhysical_gpus:\n",
    "#     tf.config.set_logical_device_configuration(\n",
    "#         gpu,\n",
    "#         [tf.config.LogicalDeviceConfiguration(memory_limit=2048)]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22feb61-7bd9-411b-b2f9-396beb328a20",
   "metadata": {},
   "source": [
    "allocate memory only when GPU needs it (must be done immediately after importing TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f229e1c-9ebe-4d25-94d7-26f081394917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gpu in physical_gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f61905-ee1e-43e5-b7ab-6bd18a088acc",
   "metadata": {},
   "source": [
    "Split on two or more logical devices (after importing TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aaee0a78-c5ca-42f2-9746-53a313759b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.set_logical_device_configuration(\n",
    "#     physical_gpus[0],\n",
    "#     [tf.config.LogicalDeviceConfiguration(memory_limit=2048),\n",
    "#      tf.config.LogicalDeviceConfiguration(memory_limit=2048)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ed405-41d2-47bc-825e-a0325538bc53",
   "metadata": {},
   "source": [
    "You generally want to place the data preprocessing operations on the CPU, and place the neural network operations on the GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae012446-bf3d-4f75-999b-6dd693b80543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable([1., 2., 3.]) # float32 variable goes to the GPU (in my case CPU on an M1 mac)\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa6095ee-7273-4b49-9961-2f34ce4d7901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.Variable([1, 2, 3]) # int32 variable goes to the CPU\n",
    "b.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982be051-a25f-4ada-8119-41686272737b",
   "metadata": {},
   "source": [
    "M1 Mac has a multithreaded kernel so any oepration can be run parallel across multiple cores!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c41c05-52c1-47bd-a077-67f4486d2d0b",
   "metadata": {},
   "source": [
    "Operations in the CPU's evaluation queue are dispatched to a thread pool called the inter-op thread pool.\n",
    "\n",
    "a second thread pool called the intra-op thread pool (shared by all multithreaded CPU kernels).\n",
    "\n",
    "control the number of threads in the inter-op thread pool by calling:\n",
    "`tf.config.threading.set_intra_op_parallelism_threads()`\n",
    "This is useful if you do not want TensorFlow to use all the CPU cores or if you want it to be single-threaded.\n",
    "\n",
    "You could train a model on a single GPU and perform all the preprocessing in parallel on the CPU, using the dataset's prefetch() method\n",
    "\n",
    "CNNs contain layers that are partially connected to the lower layers so its much easier to distribute chunks across devices efficiently\n",
    "\n",
    "Deep RNN can be split up eddiciently across multiple GPUs if its split up horizontally (per layer)\n",
    "\n",
    "Split up the data and train on a different set of data per GPU (follow thje mirrored strat)\n",
    "\n",
    "There are a few ways you can reduce the effect of stale gradients:\n",
    "- Reduce the learning rate.\n",
    "- Drop stale gradients or scale them down.\n",
    "- Adjust the mini-batch size.\n",
    "- Start the first few epochs using just one replica (this is called the warmup phase).\n",
    "\n",
    "Stale gradients tend to be more damaging at the beginning of training, when gradients are typically large and the parameters have not settled into a valley of the cost function yet, so different replicas may push the parameters in quite different directions.\n",
    "\n",
    "pipeline parallelism, which combines model parallelism and data parallelism: the model is chopped into consecutive parts, called stages, each of which is trained on a different machine. This results in an asynchronous pipeline in which all machines work in parallel with very little idle time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d485533-eaca-4fdd-84ef-1bc3a3953b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Epoch 1/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.6405 - val_accuracy: 0.9481 - val_loss: 0.1906\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1788 - val_accuracy: 0.9613 - val_loss: 0.1400\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.1286 - val_accuracy: 0.9665 - val_loss: 0.1196\n",
      "Epoch 4/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0970 - val_accuracy: 0.9682 - val_loss: 0.1063\n",
      "Epoch 5/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.0781 - val_accuracy: 0.9702 - val_loss: 0.1005\n",
      "Epoch 6/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0636 - val_accuracy: 0.9690 - val_loss: 0.1001\n",
      "Epoch 7/10\n",
      "\u001b[1m 60/500\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 08:37:54.603644: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0538 - val_accuracy: 0.9740 - val_loss: 0.0866\n",
      "Epoch 8/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0437 - val_accuracy: 0.9750 - val_loss: 0.0859\n",
      "Epoch 9/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0359 - val_accuracy: 0.9752 - val_loss: 0.0817\n",
      "Epoch 10/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0300 - val_accuracy: 0.9748 - val_loss: 0.0875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30b969850>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using data parallelism with the mirrored strategy\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", \n",
    "                  loss=\"sparse_categorical_crossentropy\", \n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "batch_size = 100\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47412915-02ba-4035-9ee1-ffd3162a0f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.backend.Variable"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.weights[0]) # if GPU: tensorflow.python.distribute.values.MirroredVariable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a231e7a-b159-4062-a1a1-3570e6b7a5d4",
   "metadata": {},
   "source": [
    "Load a model and run it on all available devices, you must call `tf.keras.models.load_model()` within a distribution context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39691d1-c289-45d1-8de7-b2a0bef129e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = tf.keras.models.load_model(\"my_mirrored_model\")\n",
    "\n",
    "# subset of all available GPU devices\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "# data parallelism with centralized parameters\n",
    "strategy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "\n",
    "# TPUStrategy (right after importing TensorFlow)\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6e856-bb61-447a-8f34-4dcb82dfbd9f",
   "metadata": {},
   "source": [
    "Vertex AI also includes an AutoML service, which completely takes care of finding the right model architecture and training it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b255f-e572-41ca-aac5-f726ff84c4a7",
   "metadata": {},
   "source": [
    "YouTube Channels to checkout:\n",
    "Yannic Kilcher, Letitia Parcalabescu, and Xander Steenbrugge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cefc74d-0af9-44ea-a65e-83c168dfa75f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (pyenv)",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
