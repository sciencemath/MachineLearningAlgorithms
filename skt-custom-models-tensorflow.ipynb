{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f137c0c7-ee70-4c23-b40d-36ac28caa4f8",
   "metadata": {},
   "source": [
    "### Tensors flow from operation to operation (hence the name Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96936b38-acbb-4f3f-af93-a974728fbeb9",
   "metadata": {},
   "source": [
    "similar to Numpy ndarray, a tensor can also hold a scalar.\n",
    "\n",
    "Tensors allows for a more custom solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a154cc-3d5e-4857-b654-537f5ddbdd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "t = tf.constant([[1.,2.,3.], [4.,5.,6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85740362-92ba-474d-986c-309c9b48dd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab711dc-3414-4891-9630-34b4cb6c46e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34f2585a-5484-47dd-8827-7dcf57baf27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb19ae4-6927-43a6-82a6-bdcb097c915a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46570b-a9b4-4bac-928e-245031495d0d",
   "metadata": {},
   "source": [
    "Use `tf.reshape()` when you need to rearrange elements without adding or removing data.\n",
    "\n",
    "Use `tf.newaxis` when you need to expand dimensions (e.g., add batch/channel axes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb07f3c-b36e-4855-9560-fe7fe5e7df80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6311428-a129-4318-a8d4-861b4cb92d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8918940e-283e-47b4-bdaf-492085a82ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4677e148-2ea4-43e1-a50d-75213dc03e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=69>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(69)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb44176-4a14-4af3-9573-5876d97b22da",
   "metadata": {},
   "source": [
    "numpy transpose `t.T` is different than `tf.transpose(t)` numpy modifies the same data and tensorflow returns a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f50f01eb-95c4-422d-b647-8a01d80178f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([2.,4.,5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7024c383-2d0b-4627-89cc-1f9bf95216d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a2288d3-54ad-4e18-981e-096e948cdcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e60cd2d-ca5d-473d-8b7e-ece9da7dfd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc5a13-988a-4728-91f3-2e0018f0a2ff",
   "metadata": {},
   "source": [
    "NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit. 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less\n",
    "RAM. When you create a tensor from a NumPy array, make sure to set dtype=tf.float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ccdbea3-c1f4-4615-be62-0f66027f473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These throws errors because we cannot convert datatyes\n",
    "# tf.constant(2.) + tf.constant(40)\n",
    "# tf.constant(2.) + tf.constant(40, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a70c4a06-ea83-480d-87f8-ef1ee207e448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d3b9020-1c65-4120-8b3a-cb93238b625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1.,2.,3.], [4.,5.,6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25cb4d-f2f1-4f10-82af-f2dffa3a3585",
   "metadata": {},
   "source": [
    "TensorFlow Variables allows us to modify operations in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e4d92c2-36a9-4446-9639-e369c2571793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98d1a555-331d-41ff-abf9-b220e9231c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 69.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "055d9740-bb33-4175-8839-3edb3ae2d66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 69.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98e1e538-5b1e-44c9-8730-ec5ffc2f97fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  69.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0,0], [1,2]], updates=[100., 200.]) # updating slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d91ff355-2d2a-4ad1-aa54-c2f0f6b0e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct assignment won't work\n",
    "# v[1] = [7.,8.,9.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c049d74-49e8-4424-bdd4-82a306024bfe",
   "metadata": {},
   "source": [
    "### Custom Loss function\n",
    "\n",
    "used when you need something custom say when your data is noisy and MSE is not enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b749e-fe46-48e4-b01d-709c6e1f23c8",
   "metadata": {},
   "source": [
    "`tf.keras.losses.Huber` is built in but here we can define our own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac87fdeb-ab02-4c50-88fe-8873ddcdd89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f32cf-f5e2-4d9f-9e56-3f7d7ad7e7b2",
   "metadata": {},
   "source": [
    "its not recommended to return the mean loss as it makes it impossible to use class weights or sample weights when you need them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8767b120-0410-450d-9999-4fdf12db5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=huber_fn, optimizer=\"nadam\")\n",
    "# model.fit(X_train, y_train, [...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d385a851-4178-44e4-8830-6000cf121257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model containing custom objects\n",
    "# model = tf.keras.models.load_model(\"my_model_with_a_custom_loss\", custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b3db93-6eb3-474c-a426-74fd08954fe3",
   "metadata": {},
   "source": [
    "any error between -1 and 1 is considered small, if we want a different threshold we can create a custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8621f86d-cfcb-4603-91f2-2f66492e0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold ** 2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn\n",
    "\n",
    "# model.compile(loss=create_huber(2.0), optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a92f84f-f036-4e4d-b07c-b0296144b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model with custom threshold\n",
    "# model = tf.keras.models.load_model(\"my_model_loss_threshold_2\", custom_objects={\"huber_fn\": create_huber(2.0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e44d7-d3e1-442d-9caa-f544efd9c66f",
   "metadata": {},
   "source": [
    "when saving a model Keras calls the loss instance `get_config()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4a62f48-6d3a-4b71-b9ec-a78ea4896cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold ** 2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}\n",
    "\n",
    "# model.compile(loss=HuberLoss(2.), optimizer=\"nadam\")\n",
    "# model = tf.keras.models.load_model(\"model_custom_loss_class\", custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53ab4c-7ab8-4dcb-b6d7-efc01e12c41c",
   "metadata": {},
   "source": [
    "### Custom activations, initializers, regularizers, and contraints\n",
    "\n",
    "- activation\n",
    "   softplus: equivalent to `tf.keras.acitivations.softplus()` or `tf.nn.softplus()`\n",
    "- initializer\n",
    "  glorot: equivalent to `tf.keras.initializers.glorot_normal()`\n",
    "- regularizer\n",
    "  L1: `tf.keras.regularizers.l1(0.01))`\n",
    "- constraints\n",
    "  weights: `tf.keras.contraints.nonneg()` or `tf.nn.relu()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad0a7d00-1c6f-4c44-bf28-ae9f6ebaf445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(1.0 + tf.exp(z))\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fec9ead0-3e64-4196-98ff-387502fb1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(1, activation=my_softplus,\n",
    "                              kernel_initializer=my_glorot_initializer,\n",
    "                              kernel_regularizer=my_l1_regularizer,\n",
    "                              kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b398459f-cad0-4fe8-9a49-a910bd79a1ac",
   "metadata": {},
   "source": [
    "### hyperparams saved with model\n",
    "\n",
    "subclass correctly from `Initializer, Layer, Constraint, Regulatizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2711b51a-8b0b-40f7-91c7-8c51d83337a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "818d9859-6cb6-4673-b436-aae64eca577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom metric:\n",
    "# model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f595bd54-bba9-4f45-a02f-97bba8ad7f4d",
   "metadata": {},
   "source": [
    "### Binary classifier precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45da41-f95e-4ef8-89e2-316a5830d416",
   "metadata": {},
   "source": [
    "1. **First batch:**\n",
    "   - **True Positives (TP)** = 4  \n",
    "   - **False Positives (FP)** = 1  \n",
    "   - **Precision** =  \n",
    "     $$ \\frac{TP}{TP + FP} = \\frac{4}{5} = 80\\% $$\n",
    "\n",
    "2. **Second batch:**\n",
    "   - **True Positives (TP)** = 0  \n",
    "   - **False Positives (FP)** = 3  \n",
    "   - **Precision** =  \n",
    "     $$ \\frac{0}{3} = 0\\% $$\n",
    "\n",
    "### Why the Mean is Wrong (Macro Averaging)\n",
    "If you simply average the two batch precisions:\n",
    "\n",
    "$$\n",
    "\\frac{80\\% + 0\\%}{2} = 40\\%\n",
    "$$\n",
    "\n",
    "This is **macro averaging**, which treats both batches equally regardless of the number of predictions in each.\n",
    "\n",
    "### Why 50% is Correct (Micro Averaging)\n",
    "The correct way to calculate **overall precision** is to sum up all **true positives** and divide by all **positive predictions** across both batches:\n",
    "\n",
    "$$\n",
    "\\frac{\\text{Total True Positives}}{\\text{Total Positive Predictions}} = \\frac{4 + 0}{5 + 3} = \\frac{4}{8} = 50\\%\n",
    "$$\n",
    "\n",
    "This is **micro averaging**, which takes into account the actual number of predictions.\n",
    "\n",
    "### Key Takeaway\n",
    "- **Macro averaging** (simple mean) can be misleading because it gives equal weight to each batch, regardless of size.\n",
    "- **Micro averaging** (overall TP / overall predictions) is usually the right way to calculate precision when looking at the model’s actual performance.\n",
    "\n",
    "That's why the correct answer is **50%**, not **40%**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c2db46e-5c51-4401-a99a-6a95c21941e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.800000011920929>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Micro averaging\n",
    "precision = tf.keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b66b3bb-3a10-4069-b1fe-04f4905560c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5bd31-4513-4716-9bbf-137ac989f953",
   "metadata": {},
   "source": [
    "^ This is overall percision not just the second batch! (streaming metric, stateful metric) updated batch after batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e775b7fe-7e39-4ad9-8569-e5545fcc1cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c77aaca7-6956-47eb-a419-682948d8e43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=precision/true_positives, shape=(1,), dtype=float32, value=[4.]>,\n",
       " <Variable path=precision/false_positives, shape=(1,), dtype=float32, value=[4.]>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11550657-417a-49f5-883a-1be1cd2cf2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98c40e03-f35a-414d-880e-0786525cbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom streaming metric\n",
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86171ebc-0709-46aa-a3b7-f159c69a44d3",
   "metadata": {},
   "source": [
    "^ Keras will take care of variable persistence no action is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c1456-591b-4295-9220-06cc4a61b0e0",
   "metadata": {},
   "source": [
    "#### layers with no weights `tf.keras.layers.Flatten`\n",
    "#### layers with no weights `tf.keras.layers.ReLU`\n",
    "\n",
    "custom layer without weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd4aeae0-c5a0-4989-aa55-4f19c096ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation=\"exponential\"\n",
    "exponential_layer = tf.keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b1117f8-a667-46a5-bee8-033bb4b9ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom stateful layer (simplified Dense layer)\n",
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "                                      initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units, \"activation\": tf.keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e2dc330-acf3-4517-b9a4-dc3b9cec44f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A layer that adds Gaussian noise during trianing but nothing for testing\n",
    "# much like tf.keras.layers.GaussianNoise\n",
    "class MyGaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=False):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79bf91d-9d96-42f6-9786-2c50cfe7265e",
   "metadata": {},
   "source": [
    "Custom Model:\n",
    "\n",
    "creating identical blocks, its more effecient to create the layers needed for the model separately. Now we have the tools to create any model we need w/ Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7cbe041-cae1-4deb-a7e9-0e8e132fc4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(\n",
    "            n_neurons, activation=\"relu\", kernel_initializer=\"he_normal\"\n",
    "        ) for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "711758b4-2b10-4e67-8cba-8b7682ccf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5937a9cf-5b49-420f-8b7d-c7261ce79e4a",
   "metadata": {},
   "source": [
    "Custom reconstruction loss (mean squared difference between the reconstruction and inputs) adding reconstruction loss to main loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b646b0f-6f75-443f-bd03-e538397ccbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = tf.keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7e582-a48d-449b-97f2-9abc2ef48126",
   "metadata": {},
   "source": [
    "### AutoDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ccbf8e5-12aa-4d92-b3f4-3d6a9e2986f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "72423437-062f-47dc-bd31-085cf7867423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8dc9f4a2-0763-49a3-b2ff-23ddd8caeeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77488a4e-05d5-46a6-80a8-79d54389a51b",
   "metadata": {},
   "source": [
    "### Reverse-mode autodiff (backprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb4b7015-1544-4ce2-99c0-00f51aed2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1a5a5fc-16f6-49f9-a7b7-23b8eac0c230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe727324-db61-4b6a-9fe2-fe57af2f59d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(36.0, shape=(), dtype=float32) tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# if we need to call gradient() more than once:\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2)\n",
    "print(dz_dw1, dz_dw2)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e769a882-c355-4e36-a137-0917f1aa2733",
   "metadata": {},
   "source": [
    "To record every operation from a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49b4b3a8-2822-4687-b666-b54ab96f6572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(w1)\n",
    "    tape.watch(w2)\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])\n",
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c2af8-a44c-4e97-b54a-d8cf0f0addf7",
   "metadata": {},
   "source": [
    "^ sometimes we need to watch because loss may be based on the gradient of activations with respect to input\n",
    "\n",
    "gradient tape is used to compute the gradients of a single value (usually the loss) with regard to a set of values (usually the model parameters).\n",
    "\n",
    "reverse-mode autodiff needs to do one forward pass and one reverse pass to get all the gradients at once. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69326ce-01b2-4e4b-9365-cb25a9075474",
   "metadata": {},
   "source": [
    "Jacobian for individual gradients with their losses\n",
    "\n",
    "Hessians for second-order partial derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d03d15-b6dd-435f-b226-898829134eb7",
   "metadata": {},
   "source": [
    "stopping backprop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb2265b9-e1da-4bb0-b8da-4c2832cc554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])\n",
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85ef0e-b986-401b-b960-b71aa78a449d",
   "metadata": {},
   "source": [
    "computing a gradient might be infinite\n",
    "\n",
    "add a tiny value to x such as 1/1_000_000 or 10^-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "11f10c61-b614-4eba-b26f-614febfd3373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=inf>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(1e-50)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = tf.sqrt(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9384a83-bff0-4f32-b68c-df08cbda1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stable gradients\n",
    "@tf.custom_gradient\n",
    "def my_softplus(z):\n",
    "    def my_softplus_gradients(grads):\n",
    "        return grads * (1 - 1 / (1 + tf.exp(z)))\n",
    "\n",
    "    result = tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)\n",
    "    return result, my_softplus_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67cce4-ba2e-4e92-b38c-4a79fd258a0b",
   "metadata": {},
   "source": [
    "derivative of `log(1 + exp(z)) = exp(z) / (1 + exp(z))` not stable for large z\n",
    "\n",
    "with a bit of algebraic manipulation, it’s also equal to `1 – 1 / (1 + exp(z))`, which is stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eee5f9-ca9d-4f7e-a1ad-5c7b7a5fe65a",
   "metadata": {},
   "source": [
    "### Creating a custom Training loop\n",
    "\n",
    "most of the time you will just need `fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "91aea49c-8c6e-43be-a9ca-ea8d51886ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = tf.keras.regularizers.l2(0.05)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2_reg),\n",
    "    tf.keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa7325ce-6f0e-4a4c-a353-bdf677bd3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b69752c-79ef-4515-8444-6aceb1c8a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(step, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([f\"{m.name}: {m.result():.4f}\"\n",
    "                          for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if step < total else \"\\n\"\n",
    "    print(f\"\\r{step}/{total} - \" + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "127fc8fe-a55c-417f-b0b4-3db54be4dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.randn(320, 5).astype(np.float32)  # Input features\n",
    "y_train = (2 * X_train[:, 0] + 3 * X_train[:, 1] + np.random.randn(320)).astype(np.float32)  # Target values\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "mean_loss = tf.keras.metrics.Mean(name=\"mean_loss\")\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "faeb02e0-8abb-4610-87ab-7b7f9f5af9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/mathias/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.1-cp312-cp312-macosx_14_0_arm64.whl (24.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "805951b6-bad8-49d7-8091-b2eb390a68d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 - mean_loss: 9.0646 - mean_absolute_error: 2.0229\n",
      "Epoch 2/5\n",
      "10/10 - mean_loss: 5.5665 - mean_absolute_error: 1.3082\n",
      "Epoch 3/5\n",
      "10/10 - mean_loss: 4.7882 - mean_absolute_error: 1.1024\n",
      "Epoch 4/5\n",
      "10/10 - mean_loss: 4.0188 - mean_absolute_error: 0.8930\n",
      "Epoch 5/5\n",
      "10/10 - mean_loss: 4.1662 - mean_absolute_error: 0.9681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Standardize features\n",
    "\n",
    "# training loop!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "\n",
    "        print_status_bar(step, n_steps, mean_loss, metrics)\n",
    "\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be66fc58-cd4b-4730-b56a-3952dc200c22",
   "metadata": {},
   "source": [
    "### Tensorflow functions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd88360e-5f45-4076-8d4c-cdb86d7e47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3fc8d5bf-f0f6-4046-814a-d98c63a35810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec2ada42-ec68-40fe-9b32-ad3ec2d88e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e9ffa26-de8c-4360-aaf2-7b6d47f31992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x15f7936b0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5fe32fcc-bc17-4020-a0d3-3032a2da9bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have the same results but as tensors\n",
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9d176923-5aa8-4821-8e38-bdf0157e2047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c553ee2f-6a8c-48f5-8943-4f94dd0fcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is more common:\n",
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5709672-71fd-437f-b7cd-1b8eb35ec4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9983d-4aab-40ec-9ad7-8112b03d9f8d",
   "metadata": {},
   "source": [
    "When you want to improve the performance of a python function just turn it into a tensor!\n",
    "\n",
    "`jit_compile=True` when calling `tf.function()` will use accelerated linear algebra (XLA) can fuse mutiple operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5871e9-9b69-44fb-b202-d2be70a811fd",
   "metadata": {},
   "source": [
    "any custom function for a keras model is a TF function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc9dab-bd59-4b88-85c7-fc51b879d6ea",
   "metadata": {},
   "source": [
    "If you call a TF function many times with different Python values, then many graphs will be generated, slowing down your program and using up a lot of RAM (you must delete the TF\n",
    "function to release it)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77dbca6-0952-4682-9bf5-4f5c82ae4775",
   "metadata": {},
   "source": [
    "TensorFlow graphs are an optimized computational representation of your Python functions\n",
    "`tf.autograph.to_code(sum_squares.python_function)` helps debug auto graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eababa27-f677-4d0b-9119-518c00c1f0dc",
   "metadata": {},
   "source": [
    "in order to get proper side effects in tf functions use: `tf.print()`\n",
    "\n",
    "Always prefer vectorized implementation whenever you can, rather than loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c00f4f-104e-44d4-a260-bc0dcc723a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (pyenv)",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
